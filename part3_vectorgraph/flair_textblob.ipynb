{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9bf1cc-5eb6-41b7-bea2-498b027e2fc8",
   "metadata": {},
   "source": [
    "## Sentiment generation\n",
    "\n",
    "Generates new columns with the flair sentiment (vflair), flair confidence (cflair), and analogous for blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0dc6c-0206-4588-9ea7-297de1c77a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5623f-340e-4cd8-9a1f-153afa86f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [\"flair\",\"spacy\",\"spacytextblob\"]\n",
    "\n",
    "import sys\n",
    "import os.path\n",
    "from subprocess import check_call\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "def instala(modules):\n",
    "  print(\"Instalando módulos\")\n",
    "  for m in modules:\n",
    "      # para el import quitamos [...] y ==...\n",
    "      p = m.find(\"[\")\n",
    "      mi = m if p==-1 else m[:p]\n",
    "      p = mi.find(\"==\")\n",
    "      mi = mi if p==-1 else mi[:p]\n",
    "\n",
    "      torch_loader = importlib.util.find_spec(mi)\n",
    "      if torch_loader is not None:\n",
    "          print(m,\" encontrado\")\n",
    "      else:\n",
    "          print(m,\" No encontrado, instalando...\",end=\"\")  \n",
    "          try:        \n",
    "            r = check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", m])\n",
    "            print(\"¡hecho!\")\n",
    "          except:\n",
    "            print(\"¡Problema al instalar \",m,\"! ¿seguro que el módulo existe?\",sep=\"\")\n",
    "              \n",
    "  print(\"¡Terminado!\")\n",
    "\n",
    "instala(modules) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041cb31-51b3-4f05-8eb2-3b18d264a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipelines = ['en_core_web_lg']\n",
    "pipelines = ['en_core_web_lg']\n",
    "def instala_pipelines(pipelines):\n",
    "  print(\"Instalando pipelines de Spacy\")\n",
    "  for p in pipelines:\n",
    "      print(\"Instalando \",p)\n",
    "      try:\n",
    "        r = check_call([sys.executable, \"-m\", \"spacy\", \"download\", p])\n",
    "        print(\"¡Hecho!\")\n",
    "      except:\n",
    "        print(\"¡Problema al instalar \",p,\"! ¿seguro que el pipeline existe?\",sep=\"\")\n",
    "\n",
    "  print(\"¡Terminado!\")\n",
    "\n",
    "instala_pipelines(pipelines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db41852-a767-421f-9da2-0ab500e9351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.data import Sentence\n",
    "classifier = TextClassifier.load('en-sentiment')\n",
    "\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "def sentiment(s):\n",
    "\n",
    "  # flair\n",
    "  text = Sentence(s)\n",
    "\n",
    "  classifier.predict(text)\n",
    "  value = text.labels[0].to_dict()\n",
    "  #print(s)\n",
    "  if value[\"value\"]==\"NEGATIVE\":\n",
    "      vflair = -1\n",
    "  elif value[\"value\"]==\"POSITIVE\":\n",
    "      vflair = +1\n",
    "  else :\n",
    "      vflair = 0 # no sé si esto pasa\n",
    "  cflair = value[\"confidence\"]\n",
    "\n",
    "  # textblob  \n",
    "  doc = nlp(s) # this returns data of the \"sentiment\" of the text\n",
    "  vblob = doc._.blob.polarity\n",
    "  cblob = doc._.blob.subjectivity\n",
    "  return vflair,cflair, vblob,cblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29d21d-749a-4b7b-8bef-a6153acb5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for a in ['16','20','24']:\n",
    "    for p in ['dem','rep']:\n",
    "        fichIn = \"tweets\"+a+\"_\"+p+\".csv\"\n",
    "        fichOut = \"tweets\"+a+\"_\"+p+\"_sft.csv\"\n",
    "        print(fichIn,end=\" - \")\n",
    "        df = pd.read_csv(path+fichIn)\n",
    "        df[['vflair', 'cflair', 'vblob', 'cblob']] = df['Tweet'].apply(lambda tweet: pd.Series(sentiment(tweet)))\n",
    "        df.to_csv(path+fichOut,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a8227-1b73-4e29-94d1-72c392beb7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichOut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60434f35-7cf5-41fa-ad7f-dc03e3ddb96a",
   "metadata": {},
   "source": [
    "## Results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d2c9d-6b27-45c4-935b-5ba4181aa628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer,f1_score, accuracy_score, recall_score,cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay,classification_report\n",
    "def show_results(y_real,y_pred,classes):\n",
    "    print(\"Accuracy \",round(accuracy_score(y_real,y_pred),4),\\\n",
    "              \"\\nKappa \", round(cohen_kappa_score(y_real,y_pred),4))\n",
    "    print('\\nClassification Report: \\n', classification_report(y_real, y_pred))\n",
    "    cm = confusion_matrix(y_real, y_pred, labels=classes)\n",
    "    print(cm)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                display_labels=classes)\n",
    "    disp.plot()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(classification_report(y_real, y_pred))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fac953-55a3-4a60-b409-33715153b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for a in ['16','20','24']:\n",
    "    for p in ['dem','rep']:\n",
    "        fichIn = \"tweets\"+a+\"_\"+p+\"_sft.csv\"\n",
    "        df = pd.read_csv(path+fichIn)\n",
    "        df2 = df[df.vblob!=0]\n",
    "        df2[\"vblob_d\"] = df2.vblob.map(lambda x: -1 if x<0 else +1)\n",
    "        print(fichIn)\n",
    "        show_results(df2.vflair,df2.vblob_d,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cacaf94-2ed0-45e7-96f9-9e9a0fcf2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.vflair.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d3294-9738-48eb-ba2a-a816e26154d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.vblob_d.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9b24b-1f6f-4a2e-bb29-4e3757b80257",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None) \n",
    "filter = (df2.vflair ==-1) & (df2.vblob_d==1)\n",
    "df2[filter].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca893f-d1df-4f6e-83da-08f1bc654a8c",
   "metadata": {},
   "source": [
    "### Comparison with human classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b866b0-06dd-49b9-ab58-78886f6cb1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichHumanDem = \"demManual.csv\"\n",
    "fichHumanRep = \"trumpManual.csv\"\n",
    "rep = \"tweets24_rep_sft.csv\"\n",
    "dem =\"tweets24_dem_sft.csv\"\n",
    "\n",
    "dfHRep = pd.read_csv(path+fichHumanRep)\n",
    "dfHDem = pd.read_csv(path+fichHumanDem)\n",
    "dfRep = pd.read_csv(path+rep).drop_duplicates(\"Tweet\")\n",
    "dfDem = pd.read_csv(path+dem).drop_duplicates(\"Tweet\")\n",
    "print(len(dfHRep),len(dfHDem),len(dfRep),len(dfDem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d216b-98cc-4d7f-84b2-e6fb55cc8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHRep_sinNA = dfHRep[~dfHRep.Final.isna()]\n",
    "dfHDem_sinNA = dfHDem[~dfHDem.Final.isna()]\n",
    "dfRep_unique = df\n",
    "\n",
    "comunRep = pd.merge(dfHRep_sinNA, dfRep, how=\"inner\", left_on=\"Tweet\", right_on=\"Tweet\")\n",
    "comunDem = pd.merge(dfHDem_sinNA, dfDem, how=\"inner\", left_on=\"Tweet\", right_on=\"Tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93161b81-cb9b-4d9e-a008-96eefc5092c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(comunRep), len(comunDem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66370b76-2a3a-4c07-afd6-830cd9ef7b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(comunRep.Final,comunRep.vflair,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119c207-2486-45a8-935d-e3d17cea7b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comunRep[\"vblob_d\"] = comunRep.vblob.map(lambda x: -1 if x<0 else +1 if x>0 else 0)\n",
    "comunDem[\"vblob_d\"] = comunDem.vblob.map(lambda x: -1 if x<0 else +1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af462821-bcf2-4ace-ba65-6a49e01add85",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(comunRep.Final,comunRep.vblob_d,[-1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa746ab-ac3b-4e0f-a185-b9be11a9159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(comunDem.Final,comunDem.vflair,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e3693-7b43-4317-9c71-13ded2094d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(comunDem.Final,comunDem.vblob_d,[-1,0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
